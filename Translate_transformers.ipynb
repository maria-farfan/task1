{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Translate_transformers",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3cX5kV6L59s"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import FSMTForConditionalGeneration, FSMTTokenizer\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48rJgXZwr0LL"
      },
      "source": [
        "def translate_eng_to_rus(claim, model = FSMTForConditionalGeneration.from_pretrained(\"facebook/wmt19-en-ru\"), \n",
        "                         tokenizer = FSMTTokenizer.from_pretrained(\"facebook/wmt19-en-ru\")):\n",
        "    if len(claim) > 0:\n",
        "        input_ids = tokenizer.encode(claim, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(input_ids)\n",
        "        decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        return(decoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYjGs9q9tWa2"
      },
      "source": [
        "\n",
        "import re\n",
        "def clean_evidence(evidence):\n",
        "    evidence = evidence[2:-2]\n",
        "    clean = re.sub('-...-','',evidence) #clean special mark\n",
        "    clean = re.sub(\" 's \", \"'s \", clean) # son 's to son's\n",
        "    return re.sub(r'[^A-z0-9\\s\\.,\\-\\'\\\"%]+', '', clean) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}